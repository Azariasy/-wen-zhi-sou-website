#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–æœç´¢å¼•æ“æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒæŸ¥è¯¢çš„æ€§èƒ½è¡¨ç°å’Œç¼“å­˜æ•ˆæœ
"""

import sys
import time
import os
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

import document_search

def test_search_performance():
    """æµ‹è¯•æœç´¢æ€§èƒ½"""
    # æµ‹è¯•ç”¨ä¾‹
    test_queries = [
        {"query": "åå››äº”", "expected_results": "> 0", "complexity": "simple"},
        {"query": "è®¡åˆ’", "expected_results": "> 100", "complexity": "simple"},
        {"query": "ä¸­å›½ç§»åŠ¨", "expected_results": "> 0", "complexity": "simple"},
        {"query": "*æŠ¥å‘Š*", "expected_results": "> 0", "complexity": "medium"},
        {"query": "ä¼šè®®çºªè¦", "expected_results": "> 0", "complexity": "medium"},
    ]
    
    # ç´¢å¼•è·¯å¾„
    index_dir = r"C:\è½¯ä»¶\æ–‡æ™ºæœ\suoyin"
    if not os.path.exists(index_dir):
        print(f"âŒ ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {index_dir}")
        return
    
    print("ğŸš€ å¼€å§‹ä¼˜åŒ–æœç´¢å¼•æ“æ€§èƒ½æµ‹è¯•...")
    print("=" * 60)
    
    # è·å–ä¼˜åŒ–æœç´¢å¼•æ“å®ä¾‹
    engine = document_search.get_optimized_search_engine()
    
    # æ¸…ç†ç¼“å­˜ä»¥ç¡®ä¿å…¬å¹³æµ‹è¯•
    engine.clear_cache()
    
    for i, test_case in enumerate(test_queries, 1):
        query = test_case["query"]
        expected_complexity = test_case["expected_results"]
        
        print(f"\nğŸ§ª æµ‹è¯• {i}: '{query}'")
        print("-" * 40)
        
        # ç¬¬ä¸€æ¬¡æœç´¢ï¼ˆæ— ç¼“å­˜ï¼‰
        print("ğŸ“Š ç¬¬ä¸€æ¬¡æœç´¢ï¼ˆæ— ç¼“å­˜ï¼‰:")
        start_time = time.time()
        
        try:
            results = document_search.optimized_search_sync(
                query, index_dir, 
                search_mode='phrase',
                search_scope='fulltext'
            )
            first_search_time = time.time() - start_time
            print(f"â±ï¸  è€—æ—¶: {first_search_time:.2f} ç§’")
            print(f"ğŸ“„ ç»“æœæ•°é‡: {len(results)}")
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            continue
        
        # ç¬¬äºŒæ¬¡æœç´¢ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰
        print("\nğŸ’¾ ç¬¬äºŒæ¬¡æœç´¢ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰:")
        start_time = time.time()
        
        try:
            cached_results = document_search.optimized_search_sync(
                query, index_dir,
                search_mode='phrase', 
                search_scope='fulltext'
            )
            second_search_time = time.time() - start_time
            print(f"â±ï¸  è€—æ—¶: {second_search_time:.2f} ç§’")
            print(f"ğŸ“„ ç»“æœæ•°é‡: {len(cached_results)}")
            
            # è®¡ç®—æ€§èƒ½æå‡
            if first_search_time > 0:
                improvement = ((first_search_time - second_search_time) / first_search_time) * 100
                print(f"ğŸš€ ç¼“å­˜æ€§èƒ½æå‡: {improvement:.1f}%")
                
        except Exception as e:
            print(f"âŒ ç¼“å­˜æœç´¢å¤±è´¥: {e}")
    
    # ç¼“å­˜ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ç¼“å­˜ç»Ÿè®¡:")
    cache_stats = engine.get_cache_stats()
    print(f"ğŸ“¦ ç¼“å­˜æ¡ç›®æ€»æ•°: {cache_stats['total_entries']}")
    print(f"âœ… æœ‰æ•ˆç¼“å­˜æ¡ç›®: {cache_stats['valid_entries']}")
    print(f"ğŸ¯ ç¼“å­˜å‘½ä¸­æ½œåŠ›: {cache_stats['cache_hit_potential']:.1%}")

def test_different_complexities():
    """æµ‹è¯•ä¸åŒå¤æ‚åº¦æŸ¥è¯¢çš„æ€§èƒ½"""
    print("\nğŸ”¬ æµ‹è¯•ä¸åŒå¤æ‚åº¦æŸ¥è¯¢...")
    print("=" * 60)
    
    index_dir = r"C:\è½¯ä»¶\æ–‡æ™ºæœ\suoyin"
    engine = document_search.get_optimized_search_engine()
    
    # ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢
    complexity_tests = [
        {
            "name": "ç®€å•æŸ¥è¯¢",
            "query": "æŠ¥å‘Š", 
            "params": {}
        },
        {
            "name": "ä¸­ç­‰å¤æ‚åº¦æŸ¥è¯¢",
            "query": "*è®¡åˆ’*",
            "params": {"file_type_filter": ["docx", "xlsx"]}
        },
        {
            "name": "å¤æ‚æŸ¥è¯¢",
            "query": "*ä¼šè®®*çºªè¦*",
            "params": {
                "file_type_filter": ["docx", "pdf", "txt"],
                "min_size_kb": 10,
                "max_size_kb": 5000
            }
        }
    ]
    
    for test in complexity_tests:
        print(f"\nğŸ§ª {test['name']}: '{test['query']}'")
        print("-" * 30)
        
        start_time = time.time()
        try:
            results = document_search.optimized_search_sync(
                test['query'], index_dir,
                search_mode='phrase',
                search_scope='fulltext',
                **test['params']
            )
            search_time = time.time() - start_time
            print(f"â±ï¸  è€—æ—¶: {search_time:.2f} ç§’")
            print(f"ğŸ“„ ç»“æœæ•°é‡: {len(results)}")
            
            # æ€§èƒ½è¯„çº§
            if search_time < 0.5:
                rating = "ğŸŸ¢ ä¼˜ç§€"
            elif search_time < 1.0:
                rating = "ğŸŸ¡ è‰¯å¥½"
            elif search_time < 2.0:
                rating = "ğŸŸ  ä¸€èˆ¬"
            else:
                rating = "ğŸ”´ éœ€è¦ä¼˜åŒ–"
                
            print(f"ğŸ“Š æ€§èƒ½è¯„çº§: {rating}")
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")

def benchmark_vs_original():
    """åŸºå‡†æµ‹è¯•ï¼šä¼˜åŒ–æœç´¢ vs åŸå§‹æœç´¢"""
    print("\nâš”ï¸  åŸºå‡†æµ‹è¯•ï¼šä¼˜åŒ–æœç´¢ vs åŸå§‹æœç´¢")
    print("=" * 60)
    
    index_dir = r"C:\è½¯ä»¶\æ–‡æ™ºæœ\suoyin"
    test_query = "åå››äº”"
    
    # åŸå§‹æœç´¢
    print("ğŸŒ åŸå§‹æœç´¢:")
    start_time = time.time()
    try:
        original_results = document_search.search_index(
            test_query, index_dir,
            search_mode='phrase',
            search_scope='fulltext'
        )
        original_time = time.time() - start_time
        print(f"â±ï¸  è€—æ—¶: {original_time:.2f} ç§’")
        print(f"ğŸ“„ ç»“æœæ•°é‡: {len(original_results)}")
    except Exception as e:
        print(f"âŒ åŸå§‹æœç´¢å¤±è´¥: {e}")
        return
    
    # ä¼˜åŒ–æœç´¢
    print("\nğŸš€ ä¼˜åŒ–æœç´¢:")
    start_time = time.time()
    try:
        optimized_results = document_search.optimized_search_sync(
            test_query, index_dir,
            search_mode='phrase',
            search_scope='fulltext'
        )
        optimized_time = time.time() - start_time
        print(f"â±ï¸  è€—æ—¶: {optimized_time:.2f} ç§’")
        print(f"ğŸ“„ ç»“æœæ•°é‡: {len(optimized_results)}")
        
        # æ€§èƒ½å¯¹æ¯”
        if original_time > 0:
            improvement = ((original_time - optimized_time) / original_time) * 100
            print(f"\nğŸ† æ€§èƒ½æå‡: {improvement:.1f}%")
            
            if improvement > 50:
                print("ğŸ‰ æ˜¾è‘—æ€§èƒ½æå‡ï¼")
            elif improvement > 20:
                print("âœ… æ€§èƒ½æœ‰æ‰€æ”¹å–„")
            elif improvement > 0:
                print("ğŸ”§ è½»å¾®æ€§èƒ½æ”¹å–„")
            else:
                print("âš ï¸  æ€§èƒ½æ— æ˜æ˜¾æ”¹å–„")
                
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–æœç´¢å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ§ª æ–‡æ™ºæœä¼˜åŒ–æœç´¢å¼•æ“æ€§èƒ½æµ‹è¯•")
    print("ğŸ¯ ç›®æ ‡ï¼šéªŒè¯æœç´¢æ€§èƒ½ä¼˜åŒ–æ•ˆæœ")
    print("ğŸ“… " + time.strftime("%Y-%m-%d %H:%M:%S"))
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_search_performance()
        test_different_complexities()
        benchmark_vs_original()
        
        print("\n" + "=" * 60)
        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc() 